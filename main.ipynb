{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29924299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9e85af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AN√ÅLISIS EXPLORATORIO INICIAL\n",
      "======================================================================\n",
      "Shape original del dataset: (284807, 31)\n",
      "N√∫mero de transacciones totales: 284,807\n",
      "N√∫mero de fraudes: 492\n",
      "\n",
      "Distribuci√≥n de clases:\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Porcentaje de fraudes: 0.173%\n",
      "Ratio de desbalance: 578:1\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ==============================\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.3\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ==============================\n",
    "# 1. CARGA DE DATOS\n",
    "# ==============================\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AN√ÅLISIS EXPLORATORIO INICIAL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape original del dataset: {df.shape}\")\n",
    "print(f\"N√∫mero de transacciones totales: {len(df):,}\")\n",
    "print(f\"N√∫mero de fraudes: {df['Class'].sum():,}\")\n",
    "print(f\"\\nDistribuci√≥n de clases:\")\n",
    "print(df[\"Class\"].value_counts())\n",
    "print(f\"\\nPorcentaje de fraudes: {df['Class'].mean()*100:.3f}%\")\n",
    "print(f\"Ratio de desbalance: {(df['Class']==0).sum()/(df['Class']==1).sum():.0f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a09fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPROCESAMIENTO\n",
      "======================================================================\n",
      "\n",
      "1. Aplicando StandardScaler a todas las caracter√≠sticas...\n",
      "   ‚úì 30 caracter√≠sticas escaladas (media=0, std=1)\n",
      "\n",
      "2. Divisi√≥n train/test (70%/30%) con estratificaci√≥n...\n",
      "   ‚úì Train: 199,364 muestras\n",
      "   ‚úì Test:  85,443 muestras\n",
      "\n",
      "Distribuci√≥n en conjunto de entrenamiento:\n",
      "  - Clase 0 (Normal): 199,020 (99.83%)\n",
      "  - Clase 1 (Fraude): 344 (0.17%)\n",
      "  - Ratio de desbalance: 579:1\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 2. PREPROCESAMIENTO\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESAMIENTO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Separar variables predictoras y variable objetivo\n",
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Escalado de todas las variables num√©ricas\n",
    "print(\"\\n1. Aplicando StandardScaler a todas las caracter√≠sticas...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "print(f\"   ‚úì {X_scaled.shape[1]} caracter√≠sticas escaladas (media=0, std=1)\")\n",
    "\n",
    "# Divisi√≥n en train/test (70/30)\n",
    "print(\"\\n2. Divisi√≥n train/test (70%/30%) con estratificaci√≥n...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Train: {X_train.shape[0]:,} muestras\")\n",
    "print(f\"   ‚úì Test:  {X_test.shape[0]:,} muestras\")\n",
    "print(f\"\\nDistribuci√≥n en conjunto de entrenamiento:\")\n",
    "print(f\"  - Clase 0 (Normal): {(y_train==0).sum():,} ({(y_train==0).mean()*100:.2f}%)\")\n",
    "print(f\"  - Clase 1 (Fraude): {(y_train==1).sum():,} ({(y_train==1).mean()*100:.2f}%)\")\n",
    "print(f\"  - Ratio de desbalance: {(y_train==0).sum()/(y_train==1).sum():.0f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad86946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPERIMENTO: SELECCI√ìN √ìPTIMA DE k\n",
      "======================================================================\n",
      "\n",
      "Objetivo: Determinar el n√∫mero √≥ptimo de caracter√≠sticas a seleccionar\n",
      "M√©todo: Validaci√≥n cruzada con diferentes valores de k\n",
      "M√©trica: Recall (Sensibilidad) - prioritaria para detecci√≥n de fraude\n",
      "Evaluando k = 5... 10... 15... 20... 25... ‚úì\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RESULTADOS: Desempe√±o por n√∫mero de caracter√≠sticas\n",
      "----------------------------------------------------------------------\n",
      "k      Recall (Media)     Recall (Std)    Evaluaci√≥n\n",
      "----------------------------------------------------------------------\n",
      "5      0.7878           0.0050          \n",
      "10     0.8082           0.0065           ‚Üê √ìPTIMO\n",
      "15     0.7937           0.0156          \n",
      "20     0.7936           0.0078          \n",
      "25     0.7995           0.0136          \n",
      "\n",
      "======================================================================\n",
      "JUSTIFICACI√ìN DE k SELECCIONADO\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Valor √≥ptimo: k = 10\n",
      "\n",
      "üìä Razones:\n",
      "   1. Mayor sensibilidad promedio: 0.8082\n",
      "   2. Desviaci√≥n est√°ndar aceptable: 0.0065\n",
      "   3. Reducci√≥n de dimensionalidad: 67%\n",
      "   4. Balance entre complejidad y desempe√±o\n",
      "\n",
      "‚úì Resultados guardados en: k_selection_experiment.csv\n",
      "\n",
      "======================================================================\n",
      "SELECCI√ìN DE CARACTER√çSTICAS (k=10)\n",
      "======================================================================\n",
      "\n",
      "4. Aplicando SelectKBest con k=10...\n",
      "   T√©cnica: Selecci√≥n basada en tests estad√≠sticos\n",
      "   M√©trica: Informaci√≥n Mutua (detecta relaciones no lineales)\n",
      "   IMPORTANTE: Se aplica ANTES del balanceo para evitar sesgo\n",
      "\n",
      "======================================================================\n",
      "VECTOR DE CARACTER√çSTICAS SELECCIONADAS\n",
      "======================================================================\n",
      "   1. V3      (Score MI: 0.0049)\n",
      "   2. V4      (Score MI: 0.0053)\n",
      "   3. V9      (Score MI: 0.0045)\n",
      "   4. V10     (Score MI: 0.0077)\n",
      "   5. V11     (Score MI: 0.0069)\n",
      "   6. V12     (Score MI: 0.0077)\n",
      "   7. V14     (Score MI: 0.0083)\n",
      "   8. V16     (Score MI: 0.0062)\n",
      "   9. V17     (Score MI: 0.0084)\n",
      "  10. V18     (Score MI: 0.0043)\n",
      "\n",
      "======================================================================\n",
      "ESTRATEGIA DE BALANCEO\n",
      "======================================================================\n",
      "\n",
      "5. Aplicando SMOTE (Synthetic Minority Over-sampling Technique)...\n",
      "   Estrategia: Sobremuestreo de la clase minoritaria (fraudes)\n",
      "   ‚ö†Ô∏è  CR√çTICO: Se aplica SOLO sobre entrenamiento (no validaci√≥n ni test)\n",
      "   Nota: Se aplica DESPU√âS de selecci√≥n de caracter√≠sticas\n",
      "\n",
      "Distribuci√≥n DESPU√âS del balanceo:\n",
      "  - Clase 0 (Normal): 199,020 (50.00%)\n",
      "  - Clase 1 (Fraude): 199,020 (50.00%)\n",
      "  - Nuevo ratio: 1.0:1\n",
      "   ‚úì Dataset balanceado correctamente\n",
      "\n",
      "======================================================================\n",
      "RESUMEN Y GUARDADO DE ARCHIVOS\n",
      "======================================================================\n",
      "\n",
      "‚úì Escalado:          StandardScaler aplicado\n",
      "‚úì Divisi√≥n:          70% train (199,364) / 30% test (85,443)\n",
      "‚úì Selecci√≥n k:       Justificado experimentalmente (k=10)\n",
      "‚úì Selecci√≥n:         SelectKBest con Mutual Information\n",
      "‚úì Caracter√≠sticas:   10 seleccionadas de 30 originales\n",
      "‚úì Balanceo:          SMOTE aplicado SOLO en train\n",
      "\n",
      "Dimensiones finales:\n",
      "  - X_train_bal: (398040, 10)  ‚Üê CON datos sint√©ticos\n",
      "  - y_train_bal: (398040,)\n",
      "  - X_test:      (85443, 10)  ‚Üê SIN datos sint√©ticos\n",
      "  - y_test:      (85443,)\n",
      "\n",
      "‚úì Archivos guardados exitosamente:\n",
      "  - k_selection_experiment.csv  ‚Üê NUEVO: justificaci√≥n de k\n",
      "  - selected_features.csv\n",
      "  - X_train_bal.csv / y_train_bal.csv  ‚Üê CON SMOTE\n",
      "  - X_test.csv / y_test.csv            ‚Üê SIN SMOTE\n",
      "\n",
      "======================================================================\n",
      "‚úÖ PREPROCESAMIENTO COMPLETADO CORRECTAMENTE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 3. EXPERIMENTO: JUSTIFICACI√ìN DEL N√öMERO DE CARACTER√çSTICAS (k)\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENTO: SELECCI√ìN √ìPTIMA DE k\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nObjetivo: Determinar el n√∫mero √≥ptimo de caracter√≠sticas a seleccionar\")\n",
    "print(\"M√©todo: Validaci√≥n cruzada con diferentes valores de k\")\n",
    "print(\"M√©trica: Recall (Sensibilidad) - prioritaria para detecci√≥n de fraude\")\n",
    "\n",
    "# Valores de k a probar\n",
    "k_values = [5, 10, 15, 20, 25]\n",
    "results_k = []\n",
    "\n",
    "# Clasificador base para evaluar (r√°pido y robusto)\n",
    "base_clf = RandomForestClassifier(\n",
    "    n_estimators=50, \n",
    "    max_depth=10,\n",
    "    class_weight='balanced',  # Maneja desbalance sin SMOTE para esta evaluaci√≥n\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Evaluando k = \", end=\"\", flush=True)\n",
    "for k in k_values:\n",
    "    print(f\"{k}...\", end=\" \", flush=True)\n",
    "    \n",
    "    # Seleccionar k caracter√≠sticas\n",
    "    selector_temp = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "    X_train_k = selector_temp.fit_transform(X_train, y_train)\n",
    "    \n",
    "    # Validaci√≥n cruzada estratificada (3-fold por eficiencia)\n",
    "    cv_scores = cross_val_score(\n",
    "        base_clf, X_train_k, y_train,\n",
    "        cv=3,\n",
    "        scoring='recall',  # Prioridad: detectar fraudes\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    results_k.append({\n",
    "        'k': k,\n",
    "        'recall_mean': cv_scores.mean(),\n",
    "        'recall_std': cv_scores.std(),\n",
    "        'cv_scores': cv_scores\n",
    "    })\n",
    "\n",
    "print(\"‚úì\\n\")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"-\"*70)\n",
    "print(\"RESULTADOS: Desempe√±o por n√∫mero de caracter√≠sticas\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'k':<6} {'Recall (Media)':<18} {'Recall (Std)':<15} {'Evaluaci√≥n'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "best_result = max(results_k, key=lambda x: x['recall_mean'])\n",
    "OPTIMAL_K = best_result['k']\n",
    "\n",
    "for res in results_k:\n",
    "    marker = \" ‚Üê √ìPTIMO\" if res['k'] == OPTIMAL_K else \"\"\n",
    "    print(f\"{res['k']:<6} {res['recall_mean']:.4f}           \"\n",
    "          f\"{res['recall_std']:.4f}          {marker}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"JUSTIFICACI√ìN DE k SELECCIONADO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n‚úÖ Valor √≥ptimo: k = {OPTIMAL_K}\")\n",
    "print(f\"\\nüìä Razones:\")\n",
    "print(f\"   1. Mayor sensibilidad promedio: {best_result['recall_mean']:.4f}\")\n",
    "print(f\"   2. Desviaci√≥n est√°ndar aceptable: {best_result['recall_std']:.4f}\")\n",
    "print(f\"   3. Reducci√≥n de dimensionalidad: {100*(1-OPTIMAL_K/30):.0f}%\")\n",
    "print(f\"   4. Balance entre complejidad y desempe√±o\")\n",
    "\n",
    "# Guardar resultados del experimento\n",
    "experiment_df = pd.DataFrame(results_k)[['k', 'recall_mean', 'recall_std']]\n",
    "experiment_df.to_csv(\"k_selection_experiment.csv\", index=False)\n",
    "print(f\"\\n‚úì Resultados guardados en: k_selection_experiment.csv\")\n",
    "\n",
    "# ==============================\n",
    "# 4. SELECCI√ìN DE CARACTER√çSTICAS CON k √ìPTIMO\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SELECCI√ìN DE CARACTER√çSTICAS (k={})\".format(OPTIMAL_K))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n4. Aplicando SelectKBest con k={OPTIMAL_K}...\")\n",
    "print(f\"   T√©cnica: Selecci√≥n basada en tests estad√≠sticos\")\n",
    "print(f\"   M√©trica: Informaci√≥n Mutua (detecta relaciones no lineales)\")\n",
    "print(f\"   IMPORTANTE: Se aplica ANTES del balanceo para evitar sesgo\\n\")\n",
    "\n",
    "# SelectKBest con k √≥ptimo\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=OPTIMAL_K)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Obtener caracter√≠sticas seleccionadas\n",
    "selected_features = X_train.columns[selector.get_support()].tolist()\n",
    "\n",
    "# Mostrar scores\n",
    "scores = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Score': selector.scores_\n",
    "}).sort_values('Score', ascending=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VECTOR DE CARACTER√çSTICAS SELECCIONADAS\")\n",
    "print(\"=\"*70)\n",
    "for i, feature in enumerate(selected_features, start=1):\n",
    "    score = scores[scores['Feature'] == feature]['Score'].values[0]\n",
    "    print(f\"  {i:2d}. {feature:6s}  (Score MI: {score:.4f})\")\n",
    "\n",
    "# ==============================\n",
    "# 5. BALANCEO DE CLASES (SMOTE)\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ESTRATEGIA DE BALANCEO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n5. Aplicando SMOTE (Synthetic Minority Over-sampling Technique)...\")\n",
    "print(\"   Estrategia: Sobremuestreo de la clase minoritaria (fraudes)\")\n",
    "print(\"   ‚ö†Ô∏è  CR√çTICO: Se aplica SOLO sobre entrenamiento (no validaci√≥n ni test)\")\n",
    "print(\"   Nota: Se aplica DESPU√âS de selecci√≥n de caracter√≠sticas\\n\")\n",
    "\n",
    "smote = SMOTE(random_state=RANDOM_SEED)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train[selected_features], y_train)\n",
    "\n",
    "print(\"Distribuci√≥n DESPU√âS del balanceo:\")\n",
    "print(f\"  - Clase 0 (Normal): {(y_train_bal==0).sum():,} ({(y_train_bal==0).mean()*100:.2f}%)\")\n",
    "print(f\"  - Clase 1 (Fraude): {(y_train_bal==1).sum():,} ({(y_train_bal==1).mean()*100:.2f}%)\")\n",
    "print(f\"  - Nuevo ratio: {(y_train_bal==0).sum()/(y_train_bal==1).sum():.1f}:1\")\n",
    "print(\"   ‚úì Dataset balanceado correctamente\")\n",
    "\n",
    "# ==============================\n",
    "# GUARDAR RESULTADOS\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN Y GUARDADO DE ARCHIVOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n‚úì Escalado:          StandardScaler aplicado\")\n",
    "print(f\"‚úì Divisi√≥n:          70% train ({X_train.shape[0]:,}) / 30% test ({X_test.shape[0]:,})\")\n",
    "print(f\"‚úì Selecci√≥n k:       Justificado experimentalmente (k={OPTIMAL_K})\")\n",
    "print(f\"‚úì Selecci√≥n:         SelectKBest con Mutual Information\")\n",
    "print(f\"‚úì Caracter√≠sticas:   {OPTIMAL_K} seleccionadas de {X_scaled.shape[1]} originales\")\n",
    "print(f\"‚úì Balanceo:          SMOTE aplicado SOLO en train\")\n",
    "\n",
    "print(f\"\\nDimensiones finales:\")\n",
    "print(f\"  - X_train_bal: {X_train_bal.shape}  ‚Üê CON datos sint√©ticos\")\n",
    "print(f\"  - y_train_bal: {y_train_bal.shape}\")\n",
    "print(f\"  - X_test:      {X_test[selected_features].shape}  ‚Üê SIN datos sint√©ticos\")\n",
    "print(f\"  - y_test:      {y_test.shape}\")\n",
    "\n",
    "pd.Series(selected_features).to_csv(\"selected_features.csv\", index=False, header=False)\n",
    "X_train_bal.to_csv(\"X_train_bal.csv\", index=False)\n",
    "y_train_bal.to_csv(\"y_train_bal.csv\", index=False, header=True)\n",
    "X_test[selected_features].to_csv(\"X_test.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False, header=True)\n",
    "\n",
    "print(\"\\n‚úì Archivos guardados exitosamente:\")\n",
    "print(\"  - k_selection_experiment.csv  ‚Üê NUEVO: justificaci√≥n de k\")\n",
    "print(\"  - selected_features.csv\")\n",
    "print(\"  - X_train_bal.csv / y_train_bal.csv  ‚Üê CON SMOTE\")\n",
    "print(\"  - X_test.csv / y_test.csv            ‚Üê SIN SMOTE\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ PREPROCESAMIENTO COMPLETADO CORRECTAMENTE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
